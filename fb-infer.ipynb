{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5306ed13",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:36.321201Z",
     "iopub.status.busy": "2022-07-15T09:17:36.320748Z",
     "iopub.status.idle": "2022-07-15T09:17:48.238850Z",
     "shell.execute_reply": "2022-07-15T09:17:48.237089Z"
    },
    "papermill": {
     "duration": 11.931176,
     "end_time": "2022-07-15T09:17:48.242681",
     "exception": false,
     "start_time": "2022-07-15T09:17:36.311505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__: 1.11.0+cpu\n",
      "tokenizers.__version__: 0.12.1\n",
      "transformers.__version__: 4.18.0\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import datasets, transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "print(f\"torch.__version__: {torch.__version__}\")\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5749b7e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.261233Z",
     "iopub.status.busy": "2022-07-15T09:17:48.260158Z",
     "iopub.status.idle": "2022-07-15T09:17:48.268823Z",
     "shell.execute_reply": "2022-07-15T09:17:48.267186Z"
    },
    "papermill": {
     "duration": 0.021038,
     "end_time": "2022-07-15T09:17:48.271211",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.250173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    num_workers=1\n",
    "    path=\"../input/first-trial/\"\n",
    "    config_path=path+'config.pth'\n",
    "    #config_path='../input/feedback-deberta-large-051/config.pth'\n",
    "    model=\"microsoft/deberta-base\"\n",
    "    batch_size=16\n",
    "    fc_dropout=0.2\n",
    "    target_size=3\n",
    "    max_len=256\n",
    "    seed=42\n",
    "    n_fold=4\n",
    "    trn_fold=[0]\n",
    "    gradient_checkpoint=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2d870a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.289493Z",
     "iopub.status.busy": "2022-07-15T09:17:48.288972Z",
     "iopub.status.idle": "2022-07-15T09:17:48.298260Z",
     "shell.execute_reply": "2022-07-15T09:17:48.297532Z"
    },
    "papermill": {
     "duration": 0.021375,
     "end_time": "2022-07-15T09:17:48.300054",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.278679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "\n",
    "def get_essay(essay_id, is_train=True):\n",
    "    parent_path = INPUT_DIR + 'train' if is_train else INPUT_DIR + 'test'\n",
    "    essay_path = os.path.join(parent_path, f\"{essay_id}.txt\")\n",
    "    essay_text = open(essay_path, 'r').read()\n",
    "    return essay_text\n",
    "\n",
    "def softmax(z):\n",
    "    assert len(z.shape) == 2\n",
    "    s = np.max(z, axis=1)\n",
    "    s = s[:, np.newaxis] # necessary step to do broadcasting\n",
    "    e_x = np.exp(z - s)\n",
    "    div = np.sum(e_x, axis=1)\n",
    "    div = div[:, np.newaxis] # dito\n",
    "    return e_x / div\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    y_pred = softmax(y_pred)\n",
    "    score = log_loss(y_true, y_pred)\n",
    "    return round(score, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e365872b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.315520Z",
     "iopub.status.busy": "2022-07-15T09:17:48.315134Z",
     "iopub.status.idle": "2022-07-15T09:17:48.362201Z",
     "shell.execute_reply": "2022-07-15T09:17:48.361330Z"
    },
    "papermill": {
     "duration": 0.057562,
     "end_time": "2022-07-15T09:17:48.364545",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.306983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = \"../input/feedback-prize-effectiveness/\"\n",
    "\n",
    "test = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\n",
    "submission = pd.read_csv(os.path.join(INPUT_DIR, 'sample_submission.csv'))\n",
    "test['essay_text']  = test['essay_id'].apply(lambda x: get_essay(x, is_train=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d91213b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.382053Z",
     "iopub.status.busy": "2022-07-15T09:17:48.381359Z",
     "iopub.status.idle": "2022-07-15T09:17:48.658544Z",
     "shell.execute_reply": "2022-07-15T09:17:48.656916Z"
    },
    "papermill": {
     "duration": 0.290752,
     "end_time": "2022-07-15T09:17:48.662572",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.371820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.path + 'tokenizer')\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8fd44dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.681489Z",
     "iopub.status.busy": "2022-07-15T09:17:48.681029Z",
     "iopub.status.idle": "2022-07-15T09:17:48.704931Z",
     "shell.execute_reply": "2022-07-15T09:17:48.703876Z"
    },
    "papermill": {
     "duration": 0.036823,
     "end_time": "2022-07-15T09:17:48.707504",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.670681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from text_unidecode import unidecode\n",
    "from typing import Dict, List, Tuple\n",
    "import codecs\n",
    "\n",
    "def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n",
    "    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
    "\n",
    "\n",
    "def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n",
    "    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
    "\n",
    "# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n",
    "codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
    "codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
    "\n",
    "def resolve_encodings_and_normalize(text: str) -> str:\n",
    "    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n",
    "    text = (\n",
    "        text.encode(\"raw_unicode_escape\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "    )\n",
    "    text = unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b913f9e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.724707Z",
     "iopub.status.busy": "2022-07-15T09:17:48.723704Z",
     "iopub.status.idle": "2022-07-15T09:17:48.740974Z",
     "shell.execute_reply": "2022-07-15T09:17:48.739873Z"
    },
    "papermill": {
     "duration": 0.029359,
     "end_time": "2022-07-15T09:17:48.743861",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.714502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "test['discourse_text'] = test['discourse_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "test['essay_text'] = test['essay_text'].apply(lambda x : resolve_encodings_and_normalize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b239468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.761133Z",
     "iopub.status.busy": "2022-07-15T09:17:48.760704Z",
     "iopub.status.idle": "2022-07-15T09:17:48.789259Z",
     "shell.execute_reply": "2022-07-15T09:17:48.787972Z"
    },
    "papermill": {
     "duration": 0.040486,
     "end_time": "2022-07-15T09:17:48.792006",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.751520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>essay_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Lead Making choices in life can be very diffic...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Seeking multiple opinions can help a person ma...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Position Seeking multiple opinions can help a ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>it can decrease stress levels</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Claim it can decrease stress levels [SEP]Makin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>a great chance to learn something new</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Claim a great chance to learn something new [S...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>can be very helpful and beneficial.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "      <td>Claim can be very helpful and beneficial. [SEP...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id                                     discourse_text discourse_type                                         essay_text                                               text  label\n",
       "0  a261b6e14276  D72CB1C11673  Making choices in life can be very difficult. ...           Lead  Making choices in life can be very difficult. ...  Lead Making choices in life can be very diffic...    NaN\n",
       "1  5a88900e7dc1  D72CB1C11673  Seeking multiple opinions can help a person ma...       Position  Making choices in life can be very difficult. ...  Position Seeking multiple opinions can help a ...    NaN\n",
       "2  9790d835736b  D72CB1C11673                     it can decrease stress levels           Claim  Making choices in life can be very difficult. ...  Claim it can decrease stress levels [SEP]Makin...    NaN\n",
       "3  75ce6d68b67b  D72CB1C11673             a great chance to learn something new           Claim  Making choices in life can be very difficult. ...  Claim a great chance to learn something new [S...    NaN\n",
       "4  93578d946723  D72CB1C11673               can be very helpful and beneficial.           Claim  Making choices in life can be very difficult. ...  Claim can be very helpful and beneficial. [SEP...    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEP = tokenizer.sep_token\n",
    "test['text'] = test['discourse_type'] + ' ' + test['discourse_text'] + SEP + test['essay_text']\n",
    "test['label'] = np.nan\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b52f6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.809619Z",
     "iopub.status.busy": "2022-07-15T09:17:48.808752Z",
     "iopub.status.idle": "2022-07-15T09:17:48.818862Z",
     "shell.execute_reply": "2022-07-15T09:17:48.817376Z"
    },
    "papermill": {
     "duration": 0.021803,
     "end_time": "2022-07-15T09:17:48.821367",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.799564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.text = df['text'].values\n",
    "        self.label = df['label'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = self.cfg.tokenizer.encode_plus(\n",
    "                        self.text[item],\n",
    "                        truncation=True,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=self.cfg.max_len\n",
    "                    )\n",
    "        samples = {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "        }\n",
    "\n",
    "        if 'token_type_ids' in inputs:\n",
    "            samples['token_type_ids'] = inputs['token_type_ids']\n",
    "        \n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8359b709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.837851Z",
     "iopub.status.busy": "2022-07-15T09:17:48.837426Z",
     "iopub.status.idle": "2022-07-15T09:17:48.855125Z",
     "shell.execute_reply": "2022-07-15T09:17:48.854152Z"
    },
    "papermill": {
     "duration": 0.028915,
     "end_time": "2022-07-15T09:17:48.858007",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.829092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Collate:\n",
    "    def __init__(self, tokenizer, isTrain=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.isTrain = isTrain\n",
    "        # self.args = args\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        output = dict()\n",
    "        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n",
    "        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n",
    "        if self.isTrain:\n",
    "            output[\"target\"] = [sample[\"target\"] for sample in batch]\n",
    "\n",
    "        # calculate max token length of this batch\n",
    "        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n",
    "\n",
    "        # add padding\n",
    "        if self.tokenizer.padding_side == \"right\":\n",
    "            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n",
    "            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n",
    "        else:\n",
    "            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n",
    "            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n",
    "\n",
    "        # convert to tensors\n",
    "        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n",
    "        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n",
    "        if self.isTrain:\n",
    "            output[\"target\"] = torch.tensor(output[\"target\"], dtype=torch.long)\n",
    "\n",
    "        return output\n",
    "\n",
    "collate_fn = Collate(CFG.tokenizer, isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bae8a1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.878419Z",
     "iopub.status.busy": "2022-07-15T09:17:48.877980Z",
     "iopub.status.idle": "2022-07-15T09:17:48.902236Z",
     "shell.execute_reply": "2022-07-15T09:17:48.901110Z"
    },
    "papermill": {
     "duration": 0.0379,
     "end_time": "2022-07-15T09:17:48.905122",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.867222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "    \n",
    "class MeanMaxPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanMaxPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        mean_pooling_embeddings = torch.mean(last_hidden_state, 1)\n",
    "        _, max_pooling_embeddings = torch.max(last_hidden_state, 1)\n",
    "        mean_max_embeddings = torch.cat((mean_pooling_embeddings, max_pooling_embeddings), 1)\n",
    "        return mean_max_embeddings\n",
    "\n",
    "    \n",
    "class LSTMPooling(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size, hiddendim_lstm):\n",
    "        super(LSTMPooling, self).__init__()\n",
    "        self.num_hidden_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hiddendim_lstm = hiddendim_lstm\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hiddendim_lstm, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, all_hidden_states):\n",
    "        ## forward\n",
    "        hidden_states = torch.stack([all_hidden_states[layer_i][:, 0].squeeze()\n",
    "                                     for layer_i in range(1, self.num_hidden_layers+1)], dim=-1)\n",
    "        hidden_states = hidden_states.view(-1, self.num_hidden_layers, self.hidden_size)\n",
    "        out, _ = self.lstm(hidden_states, None)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "class WeightedLayerPooling(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
    "            else nn.Parameter(\n",
    "                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n",
    "            )\n",
    "\n",
    "    def forward(self, all_hidden_states):\n",
    "        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
    "        return weighted_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c48cdc10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.923523Z",
     "iopub.status.busy": "2022-07-15T09:17:48.923129Z",
     "iopub.status.idle": "2022-07-15T09:17:48.949564Z",
     "shell.execute_reply": "2022-07-15T09:17:48.948440Z"
    },
    "papermill": {
     "duration": 0.039801,
     "end_time": "2022-07-15T09:17:48.952850",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.913049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "from torch.cuda.amp import autocast\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        \n",
    "        # gradient checkpointing\n",
    "        if self.cfg.gradient_checkpoint:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "            print(f\"Gradient Checkpointing: {self.model.is_gradient_checkpointing}\")\n",
    "        \n",
    "        self.bilstm = nn.LSTM(self.config.hidden_size, (self.config.hidden_size) // 2, num_layers=2, \n",
    "                              dropout=self.config.hidden_dropout_prob, batch_first=True,\n",
    "                              bidirectional=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.dropout4 = nn.Dropout(0.4)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        )\n",
    "        \n",
    "        \n",
    "\n",
    "    def loss(self, outputs, targets):\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(outputs, targets)\n",
    "        return loss\n",
    "    \n",
    "    def monitor_metrics(self, outputs, targets):\n",
    "        device = targets.get_device()\n",
    "        mll = log_loss(\n",
    "            targets.cpu().detach().numpy(),\n",
    "            softmax(outputs.cpu().detach().numpy()),\n",
    "            labels=[0, 1, 2],\n",
    "        )\n",
    "        return mll\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids=None, targets=None):\n",
    "        if token_type_ids:\n",
    "            transformer_out = self.model(ids, mask, token_type_ids)\n",
    "        else:\n",
    "            transformer_out = self.model(ids, mask)\n",
    "        \n",
    "        # LSTM/GRU header\n",
    "        \n",
    "        # simple CLS\n",
    "        sequence_output = transformer_out[0][:, 0, :]\n",
    "\n",
    "        \n",
    "        # Main task\n",
    "        logits1 = self.output(self.dropout1(sequence_output))\n",
    "        logits2 = self.output(self.dropout2(sequence_output))\n",
    "        logits3 = self.output(self.dropout3(sequence_output))\n",
    "        logits4 = self.output(self.dropout4(sequence_output))\n",
    "        logits5 = self.output(self.dropout5(sequence_output))\n",
    "        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n",
    "\n",
    "        if targets is not None:\n",
    "            metric = self.monitor_metrics(logits, targets)\n",
    "            return logits, metric\n",
    "        \n",
    "        return logits, 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa8325e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.972465Z",
     "iopub.status.busy": "2022-07-15T09:17:48.971154Z",
     "iopub.status.idle": "2022-07-15T09:17:48.980739Z",
     "shell.execute_reply": "2022-07-15T09:17:48.979255Z"
    },
    "papermill": {
     "duration": 0.02195,
     "end_time": "2022-07-15T09:17:48.983363",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.961413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# inference\n",
    "# ====================================================\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for data in tk0:\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        with torch.no_grad():\n",
    "            y_preds, _ = model(ids, mask)\n",
    "        y_preds = softmax(y_preds.to('cpu').numpy())\n",
    "        preds.append(y_preds)\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84f45fe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:48.999563Z",
     "iopub.status.busy": "2022-07-15T09:17:48.999159Z",
     "iopub.status.idle": "2022-07-15T09:17:49.004979Z",
     "shell.execute_reply": "2022-07-15T09:17:49.004257Z"
    },
    "papermill": {
     "duration": 0.016568,
     "end_time": "2022-07-15T09:17:49.007157",
     "exception": false,
     "start_time": "2022-07-15T09:17:48.990589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deberta_predictions = []\n",
    "test_dataset = TestDataset(CFG, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False,\n",
    "                         collate_fn=collate_fn,\n",
    "                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de7f5618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:17:49.023360Z",
     "iopub.status.busy": "2022-07-15T09:17:49.022688Z",
     "iopub.status.idle": "2022-07-15T09:18:13.955735Z",
     "shell.execute_reply": "2022-07-15T09:18:13.954477Z"
    },
    "papermill": {
     "duration": 24.944032,
     "end_time": "2022-07-15T09:18:13.958325",
     "exception": false,
     "start_time": "2022-07-15T09:17:49.014293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc06ff310d246c0a6cc3b1df50f27d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deberta_predictions = []\n",
    "for fold in [0]:\n",
    "    print(\"Fold {}\".format(fold))\n",
    "\n",
    "    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n",
    "    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "                       map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    deberta_predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62f6bbdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:18:13.978121Z",
     "iopub.status.busy": "2022-07-15T09:18:13.977616Z",
     "iopub.status.idle": "2022-07-15T09:18:13.983993Z",
     "shell.execute_reply": "2022-07-15T09:18:13.982935Z"
    },
    "papermill": {
     "duration": 0.018868,
     "end_time": "2022-07-15T09:18:13.986119",
     "exception": false,
     "start_time": "2022-07-15T09:18:13.967251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = np.mean(deberta_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9a9a528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:18:14.004659Z",
     "iopub.status.busy": "2022-07-15T09:18:14.003622Z",
     "iopub.status.idle": "2022-07-15T09:18:16.839728Z",
     "shell.execute_reply": "2022-07-15T09:18:16.838633Z"
    },
    "papermill": {
     "duration": 2.848306,
     "end_time": "2022-07-15T09:18:16.841986",
     "exception": false,
     "start_time": "2022-07-15T09:18:13.993680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n",
    "state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "                   map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31aa8765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-15T09:18:16.861987Z",
     "iopub.status.busy": "2022-07-15T09:18:16.861168Z",
     "iopub.status.idle": "2022-07-15T09:18:16.878665Z",
     "shell.execute_reply": "2022-07-15T09:18:16.877646Z"
    },
    "papermill": {
     "duration": 0.029043,
     "end_time": "2022-07-15T09:18:16.881031",
     "exception": false,
     "start_time": "2022-07-15T09:18:16.851988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective</th>\n",
       "      <th>Adequate</th>\n",
       "      <th>Effective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.024276</td>\n",
       "      <td>0.475767</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.023271</td>\n",
       "      <td>0.915313</td>\n",
       "      <td>0.061416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>0.019846</td>\n",
       "      <td>0.721259</td>\n",
       "      <td>0.258895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>0.052985</td>\n",
       "      <td>0.754418</td>\n",
       "      <td>0.192597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>0.031846</td>\n",
       "      <td>0.780358</td>\n",
       "      <td>0.187795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2e214524dbe3</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.567229</td>\n",
       "      <td>0.410165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84812fc2ab9f</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.203276</td>\n",
       "      <td>0.788716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c668ff840720</td>\n",
       "      <td>0.029061</td>\n",
       "      <td>0.780710</td>\n",
       "      <td>0.190229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>739a6d00f44a</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>0.361710</td>\n",
       "      <td>0.623591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bcfae2c9a244</td>\n",
       "      <td>0.010750</td>\n",
       "      <td>0.570769</td>\n",
       "      <td>0.418482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective  Adequate  Effective\n",
       "0  a261b6e14276     0.024276  0.475767   0.499957\n",
       "1  5a88900e7dc1     0.023271  0.915313   0.061416\n",
       "2  9790d835736b     0.019846  0.721259   0.258895\n",
       "3  75ce6d68b67b     0.052985  0.754418   0.192597\n",
       "4  93578d946723     0.031846  0.780358   0.187795\n",
       "5  2e214524dbe3     0.022606  0.567229   0.410165\n",
       "6  84812fc2ab9f     0.008008  0.203276   0.788716\n",
       "7  c668ff840720     0.029061  0.780710   0.190229\n",
       "8  739a6d00f44a     0.014698  0.361710   0.623591\n",
       "9  bcfae2c9a244     0.010750  0.570769   0.418482"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission['Ineffective'] = predictions[:, 2]\n",
    "submission['Adequate'] = predictions[:, 0]\n",
    "submission['Effective'] = predictions[:, 1]\n",
    "\n",
    "display(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 56.354564,
   "end_time": "2022-07-15T09:18:19.565934",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-15T09:17:23.211370",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2241bfa6898e41b28b320929d906ff1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "26f9c17e43d14bd5bcbdb35867f89f4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2cc06ff310d246c0a6cc3b1df50f27d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_64c887bb37d4408ebddb80bbc3d8bd62",
        "IPY_MODEL_35e16cfd08c84220af5bcff7c25107be",
        "IPY_MODEL_93c5353975e84583beed653caf1b2392"
       ],
       "layout": "IPY_MODEL_f0c7d50aa0e24ab4a71d5ff900424ceb"
      }
     },
     "35e16cfd08c84220af5bcff7c25107be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_90032c8dc8d34d2d8f046db906edd9c2",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_44aee521d7fb4ee280da7f4d1e75c339",
       "value": 1
      }
     },
     "44aee521d7fb4ee280da7f4d1e75c339": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "64c887bb37d4408ebddb80bbc3d8bd62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_26f9c17e43d14bd5bcbdb35867f89f4a",
       "placeholder": "​",
       "style": "IPY_MODEL_bfa7594c219a4b43bc6e4cb4e3714859",
       "value": "100%"
      }
     },
     "7d9aa60c9f634862b778cb85b8f088fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90032c8dc8d34d2d8f046db906edd9c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93c5353975e84583beed653caf1b2392": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7d9aa60c9f634862b778cb85b8f088fd",
       "placeholder": "​",
       "style": "IPY_MODEL_2241bfa6898e41b28b320929d906ff1d",
       "value": " 1/1 [00:07&lt;00:00,  7.23s/it]"
      }
     },
     "bfa7594c219a4b43bc6e4cb4e3714859": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f0c7d50aa0e24ab4a71d5ff900424ceb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
